# Big O

Это очень важная концепция.

Big O – это язык и метрика, которые мы используем для описания эффективности алгоритмов.

Непонимание этого полностью может навредить вам при разработке алгоритма. Мало того, что вас можно осудить строго за то, что вы не понимаете Big O, но вы также будете пытаться оценить, когда ваш алгоритм становится быстрее или медленнее.

Освойте эту концепцию.

### Аналогия

Представьте себе следующий сценарий: у вас есть файл на жестком диске, и вам нужно отправить его своему другу, который живет по на другом конце страны. Вам нужно как можно быстрее доставить файл своему другу. Как его отправить? 

Первой мыслью большинства людей была электронная почта, FTP или некоторые другие способы пересылки через интернет. Эта мысль разума, но только наполовину правильна.

Если это небольшой файл, вы, безусловно, правы. Так как если доставлять его самостоятельно на самолете это может занять 5-10 часов, чтобы добраться до аэропорта, сесть на рейс, а затем долететь и доставить его вашему другу.

Но что, если файл действительно, действительно большой? Возможно ли, что быстрее физически доставить его с помощью самолета?

Да, на самом деле. Для передачи в электронном виде один терабайт (1 ТБ) может занять более одного дня. Было бы гораздо быстрее просто пролететь по всей стране. Если ваш файл является срочным (и стоимость не является проблемой), вы можете просто сделать это.

Что делать, если не было рейсов, а вместо этого вам нужно было ехать по стране на машине? Даже тогда, для действительно огромного файла, было бы быстрее прокатиться на машине.

### Time Complexity Оценка сложности выполнения временем

Big O можно представить в виде графика, где ось Y – время необходимое для выполнения алгоритма или задачи, а ось X – размер файла, как в примере с прошлой задачей или в общем представлении – размер объекта, над которым необходимо совершить работу.

Представим что размер файла 5 GB, и скорость передачи по интернету 1 GB в час.

Мы могли бы описать алгоритм «алгоритм передачи данных» как:

* Передача через интернет: O(5), ( читается как “О от пяти” ), где 5 - размер файла. Это означает, что время передачи файла увеличивается линейно с размером файла. (Да, это немного упрощение, но для этих целей это нормально). То есть если файл будет 7 GB, то сложность этого алгоритма будет O(7) – О от семи.

* Передача самолетом: 0(1), ( читается как “О от одного”) относительно размера файла. По мере увеличения размера файла времени больше не потребуется, чтобы передать файл для вашего друга. Время постоянное, так как можно за один раз перевести файл очень большого размера.

Независимо от того, насколько велика константа (в данном примере время пересылки файла, а именно O(5),  где 5 это константа)  и насколько медленным является линейное увеличение, линейная сложность будет в какой-то момент превосходить постоянную.

А теперь давайте разберем предыдущий абзац. У нас есть 2 варианта пересылки: по интернету или самолетом. Вариант пересылки по интернету можно выразить как O(n). Вместо n подставляется реальное число, но когда нужно просто оценить алгоритм, то про реальное число не говорят, а просто: “О от n”. Значит, что время будет зависит от чего-то пропорционально. В данном примере от размера файла, так как скорость передачи файла постоянна.

В случае с самолетом сложность оценивается как O(1) “O от единицы”. Под единицей понимаем константное время за которое можно передать файл разного размера. 

Есть гораздо больше вариантов типов времени выполнения, чем это. Некоторые из наиболее распространенных из них - O(log N), O (N log N), O(N в степени 2) и O(2N). Тем не менее, нет фиксированного списка возможных вариантов времени выполнения.

Вы также можете иметь несколько переменных во время выполнения. Например, время рисования забора шириной w и шириной h метров может быть описано как O(wh). Если вам нужны r слоев краски, вы можете сказать, что время равно 0 (whr).

### Big O, Big Theta, and Big Omega 
Если вы никогда не занимались Big O в академических условиях, вы, вероятно, можете пропустить этот подраздел. Это может смутить вас больше, чем поможет. 

Этот раздел в основном, чтобы прояснить двусмысленность в формулировках для людей, которые понимают, что такое Big O.

Ученые используют большие O, большие Θ (тета) и большие Ω(омега) для описания времени автономной работы.

* O (Big O) В науке Big O описывает верхнюю границу времени. Алгоритм, который печатает все значения в массиве, может быть описан как O(N), но он также может быть описан как O(W), O(N3) или O(2N) (или много других O раз). Алгоритм не менее быстрый, чем каждый из них; поэтому они являются верхними границами во время выполнения. Это похоже на отношение «меньше или равно». 

Если Бобу исполнилось X лет (я предполагаю, что никто не живет в возрасте 130 лет), тогда вы могли бы сказать: X <=13. Также было бы правильно сказать, что X <= 1,000 или X <=1,000,000. Технические это истинное утверждение (хотя и не слишком полезно). Аналогично, простой алгоритм для отображения  значений массива равен O(N), а также O(N³) или любой среде выполнения больше O(N).

* Ω (большая омега): в науке Ω – эквивалентная концепция, но для нижней границы. Чтение значений из массива равна O(N), а также O(log N) и O(1). В конце концов, вы знаете, что это не будет быстрее, чем другие.

* Θ (большая тета): в науке Θ означает как Big O, так и Ω. То есть, алгоритм равен O(N), если он равен O(N) и Ω(N). Θ дает плотную оценку на во время выполнения.

В индустрии (и, следовательно, на интервью) люди, объединили Θ и O вместе. Индустриальное понимание Big O ближе к тому, что ученые называют Θ, поскольку было бы неправильно описывать итерацию по массиву как 0 (N²). Индустрия просто скажет, что это O(N).

Для этой книги мы будем использовать Big O так как индустрия имеет тенденцию использовать его: всегда старайтесь предлагать сжатое описание времени выполнения.

### Лучший случай, худший случай и ожидаемый случай
Мы можем фактически описать нашу среду выполнения для алгоритма тремя различными способами.

Давайте посмотрим на это с точки зрения быстрого сортировки. 

Быстрая сортировка выбирает случайный элемент как «точку перестановки», а затем меняет значения в массиве таким образом, что элементы, меньшие, чем точка перестановки, появляются перед элементами, большими, чем точка перестановки.

Это дает «частичную сортировку»: тогда он рекурсивно сортирует левую и правую стороны, используя аналогичный процесс. 

**Лучший случай**: если все элементы равны, то быстрая сортировка, в среднем, просто проходит через массив один раз. Это O(N). Это фактически немного зависит от реализации быстрой сортировки. Однако есть реализации, которые будут выполняться очень быстро на отсортированном массиве.

**Худший случай**: что делать, если нам действительно не повезло, а точка перестановки неоднократно является самым большим элементом в массиве? (На самом деле это легко осуществить. Если точка перестановки выбрана как первый элемент в части массива и массив отсортирован в обратном порядке, у нас будет такая ситуация.) В этом случае наша рекурсия не делит массив пополам и не рекурсирует на каждую половину. Он просто сжимает часть массива в один элемент. Это приведет к дегенерации времени работы O(N²).

**Ожидаемый случай**: Обычно эти чудесные или ужасные ситуации не случаются. Конечно, иногда точка перестановки будет очень низкой или очень высокой, но это не произойдет снова и снова. Мы можем ожидать время выполнения O(N log N). Мы редко когда-либо обсуждаем лучшую временную сложность, потому что это не очень полезная концепция. В конце концов, мы могли бы взять по существу любой алгоритм, специальный случай – некоторый ввод, а затем получить O(1) раз в лучшем случае.

Для многих, возможно, большинства алгоритмов, худший случай и ожидаемый случай одинаковы. Иногда они разные, и нам нужно описать оба времени работы.

*Какова связь между наилучшим / худшим / ожидаемым случаем и / Θ / Ω?*

Кандидатам легко путать эти понятия (возможно, потому, что у обоих есть некоторые понятия «выше»; «ниже» и «точно»), но между этими понятиями нет особой взаимосвязи. 

Наилучшие, худшие и ожидаемые случаи описывают большое время (или большую тета) для определенных ресурсов или сценариев. Big O, Big Omega и Big Theta описывают верхнюю, нижнюю и плотную границы для времени выполнения.

### Пространственная сложность
Время – это не единственное, что имеет значение в алгоритме. Мы также могли бы заботиться о количестве памяти, или дискового пространства, требуемого для работы алгоритма.

Пространственная сложность – это параллельная концепция временной сложности. Если нам нужно создать массив размером n, это ему будет нужно O(n) места.

Если нам нужен двухуровневый массив размером n*n, то в этом случае он будет занимать O(n²) места.

```java
int sum(int n) {/*Ex 1.*/
    if (n <= 0) {
        return 0;
    }
    return n + sum(n-1);
}
```
Каждый вызов добавляет уровень в стек.

```
sum(4)
    -> sum(3)
        -> sum(2)
            -> sum(l)
                -> sum(0)
```
Каждый из этих вызовов добавляется в стек вызова и занимает реальную память.

Однако то, что у вас всего n вызовов, не означает, что он занимает O(n) места. Рассмотрим функцию ниже, которая суммирует соседние элементы между O и n:

```java
int pairSumSequence(int n) {
    int sum = 0;
    for (int i = 0; i < n; i++) {
        sum += pairSum(i, i + 1);
    }
    return sum;
}

int pairSum(int a, int b) {
    return a + b;    
}
```
Будет примерно O(n) вызовов pairSum. Однако эти вызовы не существуют одновременно в стеке вызовов, поэтому вам нужно только O(1) место.

### Отбросьте константы. 
Код O(N) кможет работать быстрее, чем 0(1) кода для определенных входных данных. Big O просто описывает скорость роста. 

По этой причине мы отбрасываем константы во время выполнения. Алгоритм, который можно было бы описать как O(2N), на самом деле является O(N). Многие люди сопротивляются этому. Они увидят код с двумя (не вложенными) циклами и продолжат это значение 0(2N). Они думают, что они более "точны". Это не так.

Рассмотрим следующий код:
**Min and Max 1**
```java 
int min = Integer.MAX_VALUE; 
int max = Integer.MIN_VALUE; 
for (int x : array) {
    if (x < min) min x; 
    if (x > max) max = x;
}
```
**Min and Max 2**
```java
int min = Integer.MAX_VALUE;
int max = Integer.MIN_VALUE;
for (int x : array) {
    if (x < min) min = x;
}
for (int x : array) {
    if (x > max) maxn = x;
}
```

Какой из них быстрее? Первый делает один цикл, а другой делает два для цикла. Но тогда первое решение имеет две строки кода для цикла for, а не одну.

Если вы собираетесь подсчитать количество инструкций, вам нужно перейти на уровень сборки и принять во внимание, что для умножения требуется больше инструкций, чем для сложения, как компилятор что-то оптимизирует, и всякое такое.

Это может быть ужасно сложно, поэтому даже не начинайте идти по этому пути. Big O позволяет нам выразить, как масштабируется среда выполнения. Нам просто нужно признать, что это не значит, что O(N) всегда лучше, чем O (N²).

### Отбросьте недоминантные условия
Что вы делаете с таким выражением, как O(N² + N)? Этот вторая N не совсем константа. Но это не особенно важно.

Мы уже говорили, что отбрасываем константы. Поэтому O(N² + N²) будет O(N²). Если нас не волнует этот последний термин N2, зачем нам заботиться о N? И не будем.

Вы должны отказаться от недоминирующих условий.
* O(N² + N) становится O(N²).
* O(N + log N) становится O(N).
* O(5 * 2ⁿ + 1000N¹¹¹) становится O(2ⁿ).

У нас еще может быть сумма во время выполнения. Например, выражение O(B² + A) не может быть уменьшено (без
некоторые специальные знания об A и B).

На следующем графике показана скорость увеличения для некоторых распространенных больших значений O.
